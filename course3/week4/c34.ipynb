{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Coursera\n",
    "### Wesleyan University Data Analysis and Interpretation Specialization\n",
    "\n",
    "Course 3: Regression Modeling in Practice<br>\n",
    "Week 4: Test a Logistic Regression Model<br>\n",
    "Author: Matt Clark\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instructions:\n",
    "\n",
    "\n",
    "> This week's assignment is to test a logistic regression model.\n",
    "> \n",
    "> Data preparation for this assignment:\n",
    "> \n",
    "> 1) If your response variable is categorical with more than two categories, you will need to collapse it down to two categories, or subset your data to select observations from 2 categories.\n",
    "> \n",
    "> 2) If your response variable is quantitative, you will need to bin it into two categories.\n",
    "> \n",
    "> The assignment:\n",
    "> \n",
    "> Write a blog entry that summarize in a few sentences 1) what you found, making sure you discuss the results for the associations between all of your explanatory variables and your response variable. Make sure to include statistical results (odds ratios, p-values, and 95% confidence intervals for the odds ratios) in your summary. 2) Report whether or not your results supported your hypothesis for the association between your primary explanatory variable and your response variable. 3) Discuss whether or not there was evidence of confounding for the association between your primary explanatory and the response variable (Hint: adding additional explanatory variables to your model one at a time will make it easier to identify which of the variables are confounding variables).\n",
    "> \n",
    "> What to Submit: Write a blog entry and submit the URL for your blog. Your blog entry should include 1) the summary of your results that addresses parts 1-3 of the assignment, 2) the output from your logistic regression model.\n",
    "> \n",
    "> Example of how to write logistic regression results:\n",
    "> \n",
    "> After adjusting for potential confounding factors (list them), the odds of having nicotine dependence were more than two times higher for participants with major depression than for participants without major depression (OR=2.36, 95% CI = 1.44-3.81, p=.0001). Age was also significantly associated with nicotine dependence, such that older older participants were significantly less likely to have nicotine dependence (OR= 0.81, 95% CI=0.40-0.93, p=.041).\n",
    "> \n",
    "> Review criteria\n",
    "> Your assessment will be based on the evidence you provide that you have completed all of the steps. When relevant, gradients in the scoring will be available to reward clarity (for example, you will get one point for submitting an inaccurate or incomplete description of your results, but two points if the description is accurate and complete). In all cases, consider that the peer assessing your work is likely not an expert in the field you are analyzing. You will be assessed equally on all parts of the assignment, and whether you post your program and output.\n",
    "Summarize in a few sentences what you found, making sure you discuss the results for the associations between all of your explanatory variables and your response variable. Make sure to include statistical results (odds ratios, p-values, and 95% confidence intervals for the odds ratios) in your summary.\n",
    "Report whether or not your results supported your hypothesis for the association between your primary explanatory variable and your response variable.\n",
    "Discuss whether or not there was evidence of confounding for the association between your primary explanatory variable and the response variable.\n",
    "Include your logistic regression output in your blog entry.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preparation:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sb\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataframe generation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = Path().resolve().parents[1]\n",
    "df = pd.read_csv(str(root_dir)+'/mycodebook.csv', low_memory=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dichotomize variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dichotomize explanatory variable PPEDUCAT\n",
    "# We bin the variable PPEDUCAT into two categories: High School or less, or something more than High School.\n",
    "\n",
    "\n",
    "\n",
    "def collapse_ppeducat (row):\n",
    "   if row >= 3 :\n",
    "       return 1.0\n",
    "   else:\n",
    "       return 0.0\n",
    "    \n",
    "df['PPEDUCAT'] = df['PPEDUCAT'].apply(collapse_ppeducat) # apply collapse_ppeducat function to dichotomize PPEDUCAT \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dichotomize explanatory variable W1_C1\n",
    "# We bin the variable W1_C1 into two categories: 0: Republican 1: Democrat\n",
    "\n",
    "di_w1_c1 = {-1: np.nan, 1: 1, 2: 0, 3: np.nan, 4: np.nan} # dictionary that maps W1_C1 variable onto 0: Republican 1: Democrat\n",
    "df = df.replace({\"W1_C1\": di_w1_c1}).dropna() # use the dictionary to map W1_C1 and drop NA values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dichotomize response variable W1_F6\n",
    "# We expclude the -1 refusals to respond, and categorize 0-5: less optimistic, 6-10: more optimistic\n",
    "\n",
    "di_w1_f6 = {-1: np.nan, 0: 0, 1: 0, 2: 0, 3: 0, 4: 0, 5: 0, 6: 1, 7: 1, 8: 1, 9: 1, 10: 1}\n",
    "df = df.replace({\"W1_F6\": di_w1_f6}).dropna() # use the dictionary to drop NA values and replace numeric values with binary.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Check code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0    329\n",
      "1.0    599\n",
      "Name: PPEDUCAT, dtype: int64\n",
      "1.0    212\n",
      "0.0    716\n",
      "Name: W1_C1, dtype: int64\n",
      "1.0    662\n",
      "0.0    266\n",
      "Name: W1_F6, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# We generate a frequency table for explanitory variables to check our coding.\n",
    "\n",
    "check = df['PPEDUCAT'].value_counts(sort=False, dropna=False)\n",
    "print (check)\n",
    "check1 = df['W1_C1'].value_counts(sort=False, dropna=True)\n",
    "print(check1)\n",
    "check2 = df['W1_F6'].value_counts(sort=False, dropna=True)\n",
    "print(check2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic regression with Education Level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.582779\n",
      "         Iterations 5\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                  W1_F6   No. Observations:                  928\n",
      "Model:                          Logit   Df Residuals:                      926\n",
      "Method:                           MLE   Df Model:                            1\n",
      "Date:                Thu, 08 Oct 2020   Pseudo R-squ.:                 0.02727\n",
      "Time:                        19:19:07   Log-Likelihood:                -540.82\n",
      "converged:                       True   LL-Null:                       -555.98\n",
      "Covariance Type:            nonrobust   LLR p-value:                 3.666e-08\n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept      0.4131      0.113      3.668      0.000       0.192       0.634\n",
      "PPEDUCAT       0.8215      0.149      5.508      0.000       0.529       1.114\n",
      "==============================================================================\n",
      "Odds Ratios\n",
      "Intercept    1.511450\n",
      "PPEDUCAT     2.273999\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "lreg1 = smf.logit(formula = 'W1_F6 ~ PPEDUCAT', data = df).fit()\n",
    "print (lreg1.summary())\n",
    "# odds ratios\n",
    "print (\"Odds Ratios\")\n",
    "print (np.exp(lreg1.params))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Odds ratios with 95% confidence intervals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Lower CI  Upper CI        OR\n",
      "Intercept  1.212072  1.884774  1.511450\n",
      "PPEDUCAT   1.697583  3.046139  2.273999\n"
     ]
    }
   ],
   "source": [
    "\n",
    "params = lreg1.params\n",
    "conf = lreg1.conf_int()\n",
    "conf['OR'] = params\n",
    "conf.columns = ['Lower CI', 'Upper CI', 'OR']\n",
    "print (np.exp(conf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic regression with Level of Education and Political Association."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.580260\n",
      "         Iterations 5\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                  W1_F6   No. Observations:                  928\n",
      "Model:                          Logit   Df Residuals:                      925\n",
      "Method:                           MLE   Df Model:                            2\n",
      "Date:                Thu, 08 Oct 2020   Pseudo R-squ.:                 0.03147\n",
      "Time:                        19:19:07   Log-Likelihood:                -538.48\n",
      "converged:                       True   LL-Null:                       -555.98\n",
      "Covariance Type:            nonrobust   LLR p-value:                 2.521e-08\n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept      0.3378      0.118      2.864      0.004       0.107       0.569\n",
      "PPEDUCAT       0.8076      0.150      5.399      0.000       0.514       1.101\n",
      "W1_C1          0.3961      0.187      2.120      0.034       0.030       0.762\n",
      "==============================================================================\n"
     ]
    }
   ],
   "source": [
    "\n",
    "lreg2 = smf.logit(formula = 'W1_F6 ~ PPEDUCAT + W1_C1', data = df).fit()\n",
    "print (lreg2.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Odds ratios with 95% confidence intervals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Lower CI  Upper CI        OR\n",
      "Intercept  1.112492  1.766325  1.401793\n",
      "PPEDUCAT   1.672679  3.006719  2.242605\n",
      "W1_C1      1.030273  2.143557  1.486085\n"
     ]
    }
   ],
   "source": [
    "\n",
    "params = lreg2.params\n",
    "conf = lreg2.conf_int()\n",
    "conf['OR'] = params\n",
    "conf.columns = ['Lower CI', 'Upper CI', 'OR']\n",
    "print (np.exp(conf))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary:\n",
    "\n",
    "Recall that at the beginning of course 1, we chose the Outlook on Life data set and our Null Hypothesis ($H_0$) postulated that there was no association between the Level of Education and Economic Optimism endorsed by survey respondents, with Alternative Hypothesis ($H_a$) that there is a significant positive association between those two variables.\n",
    "Before undertaking our logistic regression, we undertook the following variable dichotomizations:\n",
    "The variable PPEDUCAT is a categorical variable measuring the respondents' Level of Education with four levels of response:\n",
    "1) Less than High School\n",
    "2) High School\n",
    "3) Some College\n",
    "4) Bachelor's Degree or Higher\n",
    "Requiring dichotomous explanatory and response variables, we collapse these into two categories:\n",
    "0) Up to completion of High School (Less than High School or High School)\n",
    "1) More than High School (Some college or Bachelor's Degree or Higher).\n",
    "We collapsed the other explanatory and response variables similiarly, then ran our regression.\n",
    "A logistic regression of Level of Education alone, against Economic Optimism shows a significant positive association, with $p-value < 0.0001$ and Odds ratio of 2.273999. A respondent with more than a high school education between about 70% more likely and 3 times as likely to be optimistic with regard to achievement of the american dream than a respondent with a high school education or less.\n",
    "Next we observe for political party's association with economic optimism by adding it to the logistic regression model, and notice that with a p-value of 0.034, it is significantly, positively associated with economic optimism after controlling for level of education, but since the confidence intervals of our two explanatory variables overlap, we cannot say that one of these conditions is more strongly associated with economic optimism than the other.\n",
    "To recapitulate, after controlling for confounding factors, level of education is associated with economic optimism with odds ratio of 2.243 falling within a 95% confidence interval ranging from 1.673 to 3.006, and political party affiliation is associated with economic optimism with odds ratio of 1.486 falling within a 95% confidence interval between 1.030 and 2.143. We can say confidently that Level of Education is significantly positively associated with Economic Optimism, consistent with $H_a$, with Political Party Affiliation being a confounding factor.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
